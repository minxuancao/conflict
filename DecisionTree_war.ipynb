{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a C4.5 decision tree to predict conflict management outcome from provided features and visualize tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modshogun import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in ICM2004.csv using pandas. Clean data by deleting row where CM14 is empty. CM14 is a categorical variable that records conflict management outcome on a scale of 0-5(0: No management, 1: offered only, 2: unsuccessful, 3: Cease-fire, 4:Partial agreement, 5: full settlement). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5004, 238)\n"
     ]
    }
   ],
   "source": [
    "#read in csv\n",
    "df = pd.read_csv('ICM2004.csv')\n",
    "#delete rows where cm14 is empty\n",
    "df = df[np.isfinite(df['cm14'])]\n",
    "#print df.shape\n",
    "#extract train_label and train_feats\n",
    "\n",
    "label = df['cm14'].values\n",
    "\n",
    "feats = df.ix[:,df.columns !='cm14'].values.T\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide label and feature into train(80%) and test(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1.  168.   93. ...,  220.  248.  325.]\n",
      " [  13.    2.    9. ...,   15.    6.    0.]\n",
      " [  45.   75.   62. ...,   82.   86.   98.]\n",
      " ..., \n",
      " [  nan   nan   nan ...,   nan   nan   nan]\n",
      " [  nan   nan   nan ...,   nan   nan   nan]\n",
      " [  nan   nan   nan ...,   nan   nan   nan]]\n",
      "[ 2.  2.  2. ...,  2.  1.  5.]\n"
     ]
    }
   ],
   "source": [
    "#divide into train and test\n",
    "#keep 20% for test\n",
    "ntest = int(label.shape[0]*0.2)\n",
    "ntrain = label.shape[0]-ntest\n",
    "subset = np.int32(np.random.permutation(label.shape[0]))\n",
    "train_feats = feats[:,subset[0:ntrain]]\n",
    "train_labels = label[subset[0:ntrain]]\n",
    "test_feats = feats[:,subset[ntrain:ntrain+ntest]]\n",
    "test_labels = label[subset[ntrain:ntrain+ntest]]\n",
    "print train_feats\n",
    "print train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split train into train and validation and set feature array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 4004)\n"
     ]
    }
   ],
   "source": [
    "#split into train and validation\n",
    "subset = np.int32(np.random.permutation(ntrain))\n",
    "nvalidation = int(train_feats.shape[0]*0.2)\n",
    "# form training subset and validation subset\n",
    "train_subset = subset[0:ntrain-nvalidation]\n",
    "validation_subset = subset[ntrain-nvalidation:ntrain]\n",
    "\n",
    "#create a feature type np array. All our features are categorical data, so all are set to True\n",
    "feat_types = np.full((train_feats.shape[0],),True,dtype=bool)\n",
    "#print feat_types.shape\n",
    "\n",
    "print train_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method for training decision tree. Create RealFeatures and MulticlassLabels for Shogun tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_tree(feats,types,labels):\n",
    "    #initialize a tree object\n",
    "    tree = C45ClassifierTree()\n",
    "    #set labels\n",
    "    tree.set_labels(labels)\n",
    "    # supply attribute types\n",
    "    tree.set_feature_types(types)\n",
    "    #suppy training matrix and train\n",
    "    tree.train(feats)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "#create shogun features and labels from given data\n",
    "#training data\n",
    "train_feats = RealFeatures(train_feats)\n",
    "train_labels = MulticlassLabels(train_labels)\n",
    "\n",
    "#test data\n",
    "test_feats = RealFeatures(test_feats)\n",
    "test_labels = MulticlassLabels(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train decision tree using train. Use validation datasets for pruning tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove validation subset before training the tree\n",
    "train_feats.add_subset(train_subset)\n",
    "train_labels.add_subset(train_subset)\n",
    "#train the tree\n",
    "C45Tree = train_tree(train_feats,feat_types,train_labels)\n",
    "\n",
    "# remove data belonging to training subset\n",
    "train_feats.remove_subset()\n",
    "train_labels.remove_subset()\n",
    "\n",
    "# add validation subset\n",
    "train_feats.add_subset(validation_subset)\n",
    "train_labels.add_subset(validation_subset)\n",
    "\n",
    "#prune the tree\n",
    "C45Tree.prune_tree(train_feats,train_labels)\n",
    "\n",
    "train_feats.remove_subset()\n",
    "train_labels.remove_subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_data(tree,data):\n",
    "    #get classification labels\n",
    "    output = tree.apply_multiclass(data)\n",
    "    #get classification certainty\n",
    "    output_certainty = tree.get_certainty_vector()\n",
    "    return output, output_certainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check prediction results and get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.818\n"
     ]
    }
   ],
   "source": [
    "# get results\n",
    "output, output_certainty = classify_data(C45Tree,test_feats)\n",
    "accuracy = MulticlassAccuracy()\n",
    "print 'Accuracy : ' + str(accuracy.evaluate(output, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I wanted to visualize the tree. But I could not find or think of way of doing it with Shogun.\n",
    "I wanted to visualize the tree with sklearn but sklearn.DecisionTree does not handle NaN values. \n",
    "if we delete all NaN values data, then we only have one data left. This obviously is not ideal.\n",
    "I ended up deleting columns that have NaN data. Then, we would have 123 features with 5004 samples.\n",
    "As this is just a sample with plotting, I used fitted all the data to plot the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5004, 124)\n",
      "(5004, 123)\n",
      "['d1', 'd2a', 'd2b', 'd3a', 'd3b', 'd4', 'd4a', 'd5a', 'd7', 'd8', 'd9', 'd10', 'd11a', 'd11b', 'd11c', 'd11d', 'd11e', 'd12', 'd13', 'd14', 'd14a', 'd14b', 'd15', 'd16', 'd17', 'd18', 'd18a', 'd19', 'd20', 'd21', 'd22', 'd23', 'd24', 'd25', 'd26', 'd27', 'd29', 'p1', 'p2', 'p3', 'p4a', 'p4b', 'p5a', 'p5b', 'p6a', 'p6b', 'p7', 'p8a', 'p8b', 'p9a', 'p9b', 'p10b', 'p11a', 'p11b', 'p12', 'p13a', 'p13b', 'p14a', 'p14b', 'p17a', 'p17b', 'p19a', 'p19b', 'p20b', 'p21b', 'p22b', 'p23a', 'p23b', 'p24', 'p25', 'p26', 'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'rdcm', 'cm2c', 'cm3', 'cm4', 'cm9', 'cm10a', 'cm10b', 'cm44', 'd14c', 'd14d', 'p4c', 'p6ac', 'p6bc', 'p6c', 'p6d', 'p8c', 'p8d', 'p9c', 'p9d', 'p11ac', 'p11bc', 'p11', 'p14ac', 'p14bc', 'p14c', 'p14d', 'p17ac', 'p17bc', 'p17c', 'p19ac', 'p19bc', 'p19c', 'p19d', 'p20bc', 'p21bc', 'p22bc', 'p22bd', 'p23ac', 'p23bc', 'p23', 'p26a', 'p28a', 'p29a', 'cm10c', 'cm14b']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete rows where cm14 is empty\n",
    "sklearn_df = df[np.isfinite(df['cm14'])]\n",
    "sklearn_df = sklearn_df.dropna(axis=1)\n",
    "print sklearn_df.shape\n",
    "\n",
    "sklearn_labels = sklearn_df['cm14'].values\n",
    "\n",
    "sklearn_feats = sklearn_df.ix[:,sklearn_df.columns !='cm14'].values\n",
    "sklearn_feature_name = list(sklearn_df.ix[:,sklearn_df.columns !='cm14'].columns[:])\n",
    "print sklearn_feats.shape\n",
    "print sklearn_feature_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the tree and visualization. This outputs a dot file, which could be converted to ps file to visualize locally. I checked that .dot could be read in with d3 for visualization but I have not looked into it. Please see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=20, random_state=99,max_depth=3)\n",
    "clf = clf.fit(sklearn_feats,sklearn_labels)\n",
    "tree.export_graphviz(clf, out_file='tree.dot',feature_names=sklearn_feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decision tree only generated depth = 3 because otherwise the tree would grow to be too big. There are 5 cases listed in the tree while we have 6 classes. This is because all conflicts we have are conflicts with some kind of management. So, there are 0 cases with cm14 =0. The first label in each box represents categorical variable. For example, d25 represents UN involvement with 1 representing \"involvement\" and 2 representing \"no involvement\". Gini represents the quality of the split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other plans: \n",
    "1.apply dimensionality reduction, like PCA, to the data.\n",
    "2.create a heat map to visualize places of conflict on a world map.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
